import sys
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job
from pyspark.sql import functions as F

# Job parametrelerini al
args = getResolvedOptions(sys.argv, ['JOB_NAME', 'INPUT_PATH', 'OUTPUT_PATH'])

# Spark ve Glue context oluÅŸtur
sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args['JOB_NAME'], args)

print("ğŸš€ CSV to Parquet ETL Job baÅŸlatÄ±lÄ±yor...")
print(f"ğŸ“¥ Input Path: {args['INPUT_PATH']}")
print(f"ğŸ“¤ Output Path: {args['OUTPUT_PATH']}")

try:
    # CSV dosyasÄ±nÄ± oku
    print("ğŸ“Š CSV dosyasÄ± okunuyor...")
    df = spark.read.option("header", "true").csv(args['INPUT_PATH'])
    
    print(f"âœ… CSV dosyasÄ± okundu. KayÄ±t sayÄ±sÄ±: {df.count()}")
    
    # Veri tiplerini dÃ¼zelt
    print("ğŸ”„ Veri tipleri dÃ¼zeltiliyor...")
    df = df.withColumn("id", F.col("id").cast("int")) \
           .withColumn("age", F.col("age").cast("int")) \
           .withColumn("salary", F.col("salary").cast("double")) \
           .withColumn("hire_date", F.to_date(F.col("hire_date"), "yyyy-MM-dd"))
    
    # Veri dÃ¶nÃ¼ÅŸÃ¼mleri ekle
    print("ğŸ”„ Veri dÃ¶nÃ¼ÅŸÃ¼mleri yapÄ±lÄ±yor...")
    df_transformed = df.withColumn(
        "age_group",
        F.when(F.col("age") < 30, "GenÃ§")
        .when(F.col("age") < 40, "Orta YaÅŸ")
        .otherwise("Deneyimli")
    ).withColumn(
        "salary_category",
        F.when(F.col("salary") < 70000, "DÃ¼ÅŸÃ¼k")
        .when(F.col("salary") < 80000, "Orta")
        .otherwise("YÃ¼ksek")
    ).withColumn(
        "processing_date",
        F.current_date()
    )
    
    # Parquet olarak kaydet
    print("ğŸ’¾ Parquet formatÄ±nda kaydediliyor...")
    df_transformed.write.mode("overwrite").parquet(args['OUTPUT_PATH'])
    
    print("âœ… CSV to Parquet dÃ¶nÃ¼ÅŸÃ¼mÃ¼ tamamlandÄ±!")
    print(f"ğŸ“ˆ Ä°ÅŸlenen kayÄ±t sayÄ±sÄ±: {df_transformed.count()}")
    
    # Ä°statistikler
    print("\nğŸ“Š Veri Ä°statistikleri:")
    df_transformed.groupBy("department").count().show()
    df_transformed.groupBy("age_group").count().show()
        
    except Exception as e:
    print(f"âŒ ETL iÅŸlemi hatasÄ±: {str(e)}")
    raise e

finally:
    job.commit()
    print("ğŸ‰ Job tamamlandÄ±!")
