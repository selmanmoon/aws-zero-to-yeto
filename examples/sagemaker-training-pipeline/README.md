# **AWS SageMaker ile MNIST Training - w/Docker**

Bu projede MNIST veri setini PyTorch framework kullanarak CNN modeliyle AWS SageMaker'da training iÅŸlemini yapacaÄŸÄ±z. AÃ§Ä±kcasÄ± buradaki MNIST datasetini eÄŸitmek iÃ§in en base bilgisayar dahil yeterli olacaktÄ±r ama buradaki benim amacÄ±m sistemi anlatmak ama isterseniz kapsamlÄ± bir training Ã¶rneÄŸi yapabiliriz. Mesela U-Net Modeli iÃ§in bu sistemi deneyebiliriz.  

## **Ä°ki YÃ¶ntem**

Bu projeyi iki farklÄ± ÅŸekilde Ã§alÄ±ÅŸtÄ±rabilirsiniz:

1. **Otomatik Deployment (Ã–nerilen):** `deploy.sh` ve `cleanup.sh` script'lerini kullanarak tek komutla tÃ¼m iÅŸlemleri yapabilirsiniz. â†’ [Script KullanÄ±mÄ±](#script-ile-otomatik-deployment)

2. **Manuel Deployment:** AdÄ±m adÄ±m her komutu manuel olarak Ã§alÄ±ÅŸtÄ±rabilirsiniz. â†’ [Manuel AdÄ±mlar](#manuel-deployment-adÄ±mlarÄ±)

## **Mimari**
```
KullanÄ±cÄ± â†’ S3 (Veri Upload) â†’ SageMaker (Training) â†’ S3 (Model Output)
                                      â†“
                                 ECR (Docker Image)
```

## Ã–n Bilgiler

**AWS Free Tier:** Ä°lk 2 ay boyunca ml.m5.xlarge instance kullanÄ±labilir. AÃ§Ä±kcasÄ± Ã§ok gÃ¼Ã§lÃ¼ bir instance deÄŸil hatta hiÃ§ deÄŸil ama MNIST gibi kÃ¼Ã§Ã¼k veri setleri iÃ§in yeterli olacaktÄ±r. Maliyet oldukÃ§a dÃ¼ÅŸÃ¼k (~0.10 dolar civarÄ±).

**FarklÄ± Instance iÃ§in:** FarklÄ± bir instance kullanmak istediÄŸinizde `Quota Increase Request`yapmanÄ±z gerekiyor. 

**Gereksinimler:**

## Kurulum
Buradaki komutlar macOS iÃ§indir.
```bash
# AWS CLI kurulumu
brew install awscli

# Docker kurulumu
brew install docker

# Login iÅŸlemleri
aws login
# aws configure de olabilir.
docker login
```

## 1. IAM Role OluÅŸturma

SageMaker iÃ§in gerekli izinlere sahip bir IAM role oluÅŸturun. **Ãœretim ortamÄ± iÃ§in** mÃ¼mkÃ¼n olduÄŸunca dar kapsamlÄ± (leastâ€‘privilege) Ã¶zel bir IAM policy kullanmanÄ±z Ã¶nerilir. Bu policy, yalnÄ±zca bu Ã¶rnek iÃ§in gereken izinleri iÃ§ermelidir:
- Ä°lgili S3 bucket/prefix iÃ§in okuma/yazma (training verisini okuma, model Ã§Ä±ktÄ±larÄ±nÄ± yazma)
- EÄŸitim imageâ€™Ä±nÄ±n bulunduÄŸu ECR repositoryâ€™si iÃ§in gerekli `ecr:GetAuthorizationToken`, `ecr:BatchGetImage`, `ecr:GetDownloadUrlForLayer` izinleri
- Sadece bu projede kullanacaÄŸÄ±nÄ±z training job, model ve endpoint isimlerini kapsayan `sagemaker:CreateTrainingJob`, `sagemaker:DescribeTrainingJob`, `sagemaker:CreateModel`, vb. gerekli SageMaker aksiyonlarÄ±

> Not: KolaylÄ±k olmasÄ± iÃ§in **sadece deneme / geliÅŸtirme ortamÄ±nda**, geÃ§ici olarak geniÅŸ bir yÃ¶netilen policy (Ã¶r. `AmazonSageMakerFullAccess`) kullanÄ±labilir. Ancak bu policy **Ã¼retim ortamÄ±nda kullanÄ±lmamalÄ±** ve daha sonra mutlaka daraltÄ±lmalÄ±dÄ±r.
---

## Script ile Otomatik Deployment

TÃ¼m iÅŸlemleri otomatik yapmak iÃ§in iki script kullanÄ±lÄ±r:

### 1. Data HazÄ±rlama 
 
```bash
./prepare-data.sh
```

Bu script:
- âœ… S3 bucket oluÅŸturur
- âœ… MNIST verisini indirir
- âœ… Veriyi S3'e yÃ¼kler
- âœ… Bilgileri `.data-info` dosyasÄ±na kaydeder

**Not:** Bu adÄ±m sadece **bir kere** yapÄ±lÄ±r. Birden fazla training job Ã§alÄ±ÅŸtÄ±racaksanÄ±z tekrar Ã§alÄ±ÅŸtÄ±rmanÄ±za gerek yok. O yÃ¼zden ayrÄ± hazÄ±rladÄ±m. 

### 2. Model Training 

```bash
./deploy.sh
```

Bu script:
- âœ… `.data-info` dosyasÄ±ndan S3 bilgilerini okur
- âœ… IAM role kontrol eder
- âœ… ECR repository oluÅŸturur
- âœ… Docker image build edip ECR'a push eder
- âœ… SageMaker training job baÅŸlatÄ±r
- âœ… Deployment bilgilerini `.deployment-info` dosyasÄ±na kaydeder

### 3. Temizlik

```bash
./cleanup.sh
```

Script `.deployment-info` ve `.data-info` dosyalarÄ±ndan bilgileri okuyarak:
- âœ… Ã‡alÄ±ÅŸan training job'larÄ± durdurur
- âœ… S3 bucket'Ä± ve iÃ§eriÄŸini siler
- âœ… ECR repository'yi ve image'larÄ± siler
- âœ… Lokal dosyalarÄ± temizler

### Ä°ÅŸ AkÄ±ÅŸÄ±

```bash
# 1. Data hazÄ±rla (bir kere)
./prepare-data.sh

# 2. Training baÅŸlat (istediÄŸiniz kadar)
./deploy.sh
./deploy.sh  # FarklÄ± hyperparameter ile tekrar
./deploy.sh  # BaÅŸka bir model ile tekrar

# 3. Temizlik 
./cleanup.sh
```

### Ã–rnek KullanÄ±m

```bash
# Ä°lk data hazÄ±rlÄ±ÄŸÄ±
$ ./prepare-data.sh
Region: us-east-1
Bucket [mnist-training-20260103]: my-mnist-bucket
â–¶ Creating S3 bucket...
â–¶ Downloading and uploading MNIST data...
âœ“ Uploaded train_data.npy
âœ“ Uploaded train_labels.npy
âœ“ Uploaded test_data.npy
âœ“ Uploaded test_labels.npy
âœ“ Data prepared and uploaded to s3://my-mnist-bucket/mnist-data/
Next: ./deploy.sh

# Training baÅŸlat
$ ./deploy.sh
â–¶ Using existing data: s3://my-mnist-bucket/mnist-data/
SageMaker Role: MySageMakerRole
â–¶ Checking IAM role...
â–¶ Setting up ECR...
â–¶ Building and pushing Docker image...
â–¶ Starting training job...
âœ“ Deployed: mnist-training-job-20260103120000

Monitor: aws sagemaker describe-training-job --training-job-name mnist-training-job-20260103120000
Cleanup: ./cleanup.sh
```

---

## Manuel Deployment AdÄ±mlarÄ±

Manuel olarak her adÄ±mÄ± kontrol ederek ilerlemek istiyorsanÄ±z aÅŸaÄŸÄ±daki adÄ±mlarÄ± takip edin:

- S3 bucket'Ä±nÄ±za eriÅŸim izinleri

Mevcut SageMaker role'lerinizi kontrol etmek iÃ§in:

```bash
aws iam list-roles --query "Roles[?contains(RoleName, 'SageMaker')].{Name:RoleName,Arn:Arn}" --output table
```

## 2. S3 Bucket OluÅŸturma

Evet tabi ki her ÅŸeyde oladuÄŸu gibi S3 gerekiyor. Training verileri ve output iÃ§in S3 bucket'Ä± oluÅŸturun:

```bash
aws s3api create-bucket \
  --bucket mnist-training \
  --region <region> \
  --create-bucket-configuration LocationConstraint=<region>
```


## 3. MNIST Verisini S3'e YÃ¼kleme

Åimdi normalde training iÅŸlemlerinde bir dataset olur onda Ã§alÄ±ÅŸÄ±rsÄ±nÄ±z ama bizde datasetimiz direkt PyTorch Framework'ten geleceÄŸinden dolayÄ± onu ayrÄ±ca localde Ã§alÄ±ÅŸtÄ±rarak ilk bi dataseti oluÅŸturup onu da S3 ye bucketÄ±mÄ±za gÃ¶ndermemiz gerekiyor. Ki zaten bu method Ã§ok doÄŸru bir yaklaÅŸÄ±m training iÅŸlemlerinde training ve gerektiÄŸinde testler hariÃ§ diÄŸer iÅŸlemleri localde yani kendi bilgisayarÄ±nÄ±zda yapmanÄ±z daha doÄŸru bir yaklaÅŸÄ±m olur. BÃ¶ylece daha tasarruflu sistem yapmÄ±ÅŸ olursunuz. 

Nacizane tavsiyemde bu sistemlerde veya Colab te bile training yapsanÄ±z kodunuzu SOLID prensibine veya benzer bir prensib gÃ¶re hazÄ±rlamanÄ±z. Ä°sterseniz sizler iÃ§in bunlara uygun bir Ã¶rnekte yapabilirim. 

Evet lafÄ± uzatmayayÄ±m, geri dÃ¶nemlim ÅŸimdi Data-S3.py ye gerekli bilgiler girerek kodumuzu Ã§alÄ±ÅŸtÄ±ralÄ±m. `bucket_name` 

Gerekli kÃ¼tÃ¼phaneler 
```bash
pip install -r requirements.txt
```
`Data-S3.py` dosyasÄ±:
- MNIST verisini PyTorch ile indirir
- NumPy formatÄ±na Ã§evirip normalize eder
- S3 bucket'Ä±na yÃ¼kler

Script'i Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
python Data-S3.py
```

Verinin yÃ¼klediÄŸini kontrol edelim:

```bash
aws s3 ls s3://<bucket-name>/mnist-data/
```

## 4. ECR Repository OluÅŸturma

Docker image'Ä±nÄ±zÄ± saklamak iÃ§in ECR repository'si oluÅŸtuÅŸturalÄ±m. Repository adÄ±nÄ± `sagemaker-mnist` belirlendim ancak siz deÄŸiÅŸtirebilirsiniz:

```bash
aws ecr create-repository \
  --repository-name sagemaker-mnist \
  --region <region>
```

Ã‡Ä±ktÄ±da gelen `repositoryUri` ve `repositoryArn` deÄŸerlerini not edin.

## 5. Docker Image HazÄ±rlama

**Neden Docker?** SageMaker, training ortamÄ±nÄ± izole etmek ve reproducibility saÄŸlamak iÃ§in Docker container'larÄ± kullanÄ±r. Bu sayede dependency'lerinizi tam kontrol edebilir ve herhangi bir ortamda aynÄ± sonuÃ§larÄ± elde edebilirsiniz.

### Dockerfile

Ben modeli PyTorch Framerwork ile yaptÄ±ÄŸÄ±mdan Docker Hub da PyTorch Tagini aldÄ±m. DeÄŸiÅŸtirmek isterseniz Hub'a bakmanÄ±zÄ± Ã¶neririm ki her tÃ¼rlÃ¼ bakÄ±n gÃ¼ncel olduÄŸuna veya sizin train operasyonunuz farklÄ± bir PyTorch versionu gerekiyordur Docker Hub'tan bulabilirisniz:

```dockerfile
FROM pytorch/pytorch:2.9.1-cuda12.6-cudnn9-runtime

WORKDIR /opt/ml/code

ENV DATA_DIR=/opt/ml/input/data/training
ENV OUTPUT_DIR=/opt/ml/model
RUN mkdir -p "$DATA_DIR" "$OUTPUT_DIR"

COPY train.py /opt/ml/code/train.py

ENV PYTHONUNBUFFERED=1
ENV SAGEMAKER_PROGRAM=train.py

ENTRYPOINT ["python", "train.py"]
```

### train.py

Training script ÅŸu klasik yapÄ±yÄ± takip etmeli:
- Veriyi `/opt/ml/input/data/training/` yolundan okur
- Model'i `/opt/ml/model/` yoluna kaydeder
- Training metriklerini stdout'a yazdÄ±rÄ±r

### Docker Build ve Push

**Ã–nemli:** SageMaker instance'larÄ± `linux/amd64` mimarisinde Ã§alÄ±ÅŸtÄ±ÄŸÄ± iÃ§in platform belirtmek kritik Ã¶nem taÅŸÄ±r. <region>, <account-id> bilgilerini girmeyi unutmayÄ±n. 

```bash
# ECR'a login
aws ecr get-login-password --region <region> | \
  docker login --username AWS --password-stdin \
  <account-id>.dkr.ecr.<region>.amazonaws.com
```
`Login Succeeed` Ã§Ä±ktÄ±sÄ± almanÄ±z lazÄ±m. 
Burada docker i build etme normalde docker build etmek  `docker build -t <image-name>` ama burada Ã¶nemli olacak kÄ±sÄ±m ECR'a uyumluluk. ECR sunucularÄ± `linux/amd64` olduÄŸu iÃ§in onda dikkat etmeniz gerekiyor evet bilgide edindiÄŸimize gÃ¶re direkt build edip push edebiliriz.
```bash
# Build ve Push (tek komutta)
docker buildx build \
  --platform linux/amd64 \
  -t <account-id>.dkr.ecr.<region>.amazonaws.com/mnist-training:latest \
  --push \
  .
```

Push iÅŸleminin baÅŸarÄ±lÄ± olduÄŸunu doÄŸrulayalÄ±m:

```bash
aws ecr describe-images \
  --repository-name mnist-training \
  --region <region>
```

## 6. SageMaker Training Job BaÅŸlatma

Evet gelelim en Ã¶nemli kÄ±sma training kÄ±smÄ±na burada bir Ã§ok veriye ihtiyaÃ§ var. Parametreler kÄ±smÄ±ndaki deÄŸiÅŸikliklere gÃ¶re komutu dÃ¼zenleyerek komutu Ã§alÄ±ÅŸtÄ±ralÄ±m. 

```bash
aws sagemaker create-training-job \
  --training-job-name mnist-training-job-$(date +%Y%m%d%H%M%S) \
  --algorithm-specification TrainingImage=<account-id>.dkr.ecr.<region>.amazonaws.com/mnist-training:v1,TrainingInputMode=File \
  --role-arn arn:aws:iam::<account-id>:role/<sagemaker-role-name> \
  --input-data-config '[{"ChannelName":"training","DataSource":{"S3DataSource":{"S3DataType":"S3Prefix","S3Uri":"s3://<bucket-name>/mnist-data/","S3DataDistributionType":"FullyReplicated"}},"ContentType":"application/x-npy"}]' \
  --output-data-config S3OutputPath=s3://<bucket-name>/mnist-output \
  --resource-config InstanceType=ml.m5.xlarge,InstanceCount=1,VolumeSizeInGB=30 \
  --stopping-condition MaxRuntimeInSeconds=3600
```9. Temizlik

### Otomatik Temizlik (Ã–nerilen)

```bash
./cleanup.sh
```

### Manuel Temizlik

Ä°ÅŸlemler bitince kaynaklarÄ± silin:

```bash
# Ã‡alÄ±ÅŸan job'larÄ± durdur (opsiyonel)
aws sagemaker stop-training-job --training-job-name <job-name>

# S3 bucket'Ä± temizle
aws s3 rm s3://<bucket-name> --recursive
aws s3api delete-bucket --bucket <bucket-name>

# ECR repository'yi sil
aws ecr delete-repository --repository-name mnist-training --force --region <region>

# Lokal dosyalarÄ± temizle
rm -rf ./data model.tar.gz
```

---

## Hangi YÃ¶ntemi SeÃ§meliyim?

| Ã–zellik | Script (prepare + deploy) | Manuel |
|---------|--------------------------|--------|
| HÄ±z | âš¡ Ã‡ok hÄ±zlÄ± (5-10 dk) | ğŸ¢ YavaÅŸ (20-30 dk) |
| Hata riski | âœ… DÃ¼ÅŸÃ¼k | âš ï¸ YÃ¼ksek |
| Ã–ÄŸrenme | ğŸ“š Temel | ğŸ“– DetaylÄ± |
| Esneklik | ğŸ”§ Orta | ğŸ¯ YÃ¼ksek |
| Tekrar KullanÄ±m | â™»ï¸ Data bir kere hazÄ±rla | ğŸ”¨ Her seferinde tekrar |
| Cleanup | ğŸ§¹ Otomatik | ğŸ”¨ Manuel |

**Tavsiye:** 
- Ä°lk defa Ã§alÄ±ÅŸtÄ±rÄ±yorsanÄ±z veya hÄ±zlÄ± test etmek istiyorsanÄ±z â†’ **Script'leri kullanÄ±n** (`prepare-data.sh` + `deploy.sh`)
- Birden fazla training job Ã§alÄ±ÅŸtÄ±racaksanÄ±z â†’ **Kesinlikle script'leri kullanÄ±n** (data hazÄ±rlÄ±ÄŸÄ± bir kere yeter)
- Sistem'i detaylÄ± Ã¶ÄŸrenmek istiyorsanÄ±z â†’ **Manuel adÄ±mlarÄ±** takip edin

---

## 7. Training Ä°zleme

Genellikle aws sagemaker komutu Ã§alÄ±ÅŸtÄ±ktan sonra ben de bir heyecan baÅŸlÄ±yor. Belki de bu zaman kadar Ã§ok az training iÅŸlemi yaptÄ±ÄŸÄ±m iÃ§in olabilir. O yÃ¼zden sadece terminalden kontrol yapmÄ±yorum console'dan sÃ¼rekli kontrol ediyorum. O yÃ¼zden hem console hem de terminalden sÃ¼rekli kontrolleri saÄŸlÄ±yorum. 

### Console Ã¼zerinden

AWS Console > SageMaker > Training jobs bÃ¶lÃ¼mÃ¼nden job'Ä±n durumunu izleyebilirsiniz.

### Terminalden

```bash
# En son job'u listele
aws sagemaker list-training-jobs \
  --sort-by CreationTime \
  --sort-order Descending \
  --max-results 1

# Job detayÄ±
aws sagemaker describe-training-job \
  --training-job-name <job-name>

# CloudWatch loglarÄ±
aws logs tail /aws/sagemaker/TrainingJobs \
  --follow \
  --log-stream-names <job-name>/algo-1-xxxxx
```

## 8. Model Ã‡Ä±ktÄ±sÄ±nÄ± Ä°ndirme

Training tamamlandÄ±ktan sonra model S3'te `model.tar.gz` olarak saklanÄ±r:

```bash
# Model output yolunu Ã¶ÄŸren
aws sagemaker describe-training-job \
  --training-job-name <job-name> \
  --query 'ModelArtifacts.S3ModelArtifacts'

# Model'i indir
aws s3 cp s3://<bucket-name>/mnist-output/<job-name>/output/model.tar.gz ./

# AÃ§
tar -xzf model.tar.gz
```

## YaygÄ±n Hatalar ve Ã‡Ã¶zÃ¼mler

### 1. "No S3 objects found" hatasÄ±
S3 bucket'Ä±nda veri olduÄŸundan emin olun dediÄŸim gibi kontrol iyidir takÄ±ntÄ±lÄ± olunmadÄ±ÄŸÄ± sÃ¼rece:
```bash
aws s3 ls s3://<bucket-name>/mnist-data/
```

### 2. "Exec format error" hatasÄ±
Docker image'Ä± `--platform linux/amd64` ile build etmeyi unutmayÄ±n. 

### 3. IAM izin hatalarÄ±
Role'Ã¼n S3 ve SageMaker izinlerine sahip olduÄŸundan emin olun. Role'e `AmazonSageMakerFullAccess` policy'si ve S3 bucket'Ä±nÄ±za eriÅŸim izinleri ekleyin.

## Region SeÃ§imi

TÃ¼m iÅŸlemlerde aynÄ± region'Ä± kullanÄ±n. Free tier ve fiyatlandÄ±rma iÃ§in: https://aws.amazon.com/sagemaker/pricing/

## Temizlik

Ä°ÅŸlemler bitince kaynaklarÄ± silin:

```bash
# S3 bucket'Ä± temizle
aws s3 rm s3://<bucket-name> --recursive
aws s3api delete-bucket --bucket <bucket-name>

# ECR repository'yi sil
aws ecr delete-repository --repository-name mnist-training --force
```

## Son 
Evet sÃ¼per ÅŸimdi AWS Training operasyonu Ã¶ÄŸrenmiÅŸ olduk umarÄ±m bu aÅŸamaya kadar sorunsuz bir ÅŸekilde gelebilmiÅŸsinizdir. TakÄ±ldÄ±ÄŸÄ±nÄ±z bir nokta olursa hem Selman'Ä±n grubundan veya Linkedin'den ulaÅŸabilirsiniz. Elimden geldiÄŸince destek olmak isterim. 
